{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/09 14:28:44 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 10.21.11.4 instead (on interface eth0)\n",
      "23/11/09 14:28:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/09 14:28:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session WebUI Port: 4040\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession;\n",
    "from pyspark.context import SparkContext;\n",
    "\n",
    "# warehouse_location points to the default location for managed databases and tables\n",
    "from os.path import abspath\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    . builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"ISM6562 PySpark Tutorials\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc =spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # only display errors (not warnings)\n",
    "\n",
    "# note: If you have multiple spark sessions running (like from a previous notebook you've run), \n",
    "# this spark session webUI will be on a different port than the default (4040). One way to \n",
    "# identify this part is with the following line. If there was only one spark session running, \n",
    "# this will be 4040. If it's higher, it means there are still other spark sesssions still running.\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://linux:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ISM6562 PySpark Tutorials</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7feb9efa36d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Decision Tree Model\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Unnamed: 0         X1   X2         X3        X4   X5     X6     X7  \\\n",
       "0             ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2   \n",
       "1              1      20000    2          2         1   24      2      2   \n",
       "2              2     120000    2          2         2   26     -1      2   \n",
       "3              3      90000    2          2         2   34      0      0   \n",
       "4              4      50000    2          2         1   37      0      0   \n",
       "...          ...        ...  ...        ...       ...  ...    ...    ...   \n",
       "29996      29996     220000    1          3         1   39      0      0   \n",
       "29997      29997     150000    1          3         2   43     -1     -1   \n",
       "29998      29998      30000    1          2         2   37      4      3   \n",
       "29999      29999      80000    1          3         1   41      1     -1   \n",
       "30000      30000      50000    1          2         1   46      0      0   \n",
       "\n",
       "          X8     X9  ...        X15        X16        X17       X18       X19  \\\n",
       "0      PAY_3  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2   \n",
       "1         -1     -1  ...          0          0          0         0       689   \n",
       "2          0      0  ...       3272       3455       3261         0      1000   \n",
       "3          0      0  ...      14331      14948      15549      1518      1500   \n",
       "4          0      0  ...      28314      28959      29547      2000      2019   \n",
       "...      ...    ...  ...        ...        ...        ...       ...       ...   \n",
       "29996      0      0  ...      88004      31237      15980      8500     20000   \n",
       "29997     -1     -1  ...       8979       5190          0      1837      3526   \n",
       "29998      2     -1  ...      20878      20582      19357         0         0   \n",
       "29999      0      0  ...      52774      11855      48944     85900      3409   \n",
       "30000      0      0  ...      36535      32428      15313      2078      1800   \n",
       "\n",
       "            X20       X21       X22       X23                           Y  \n",
       "0      PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "1             0         0         0         0                           1  \n",
       "2          1000      1000         0      2000                           1  \n",
       "3          1000      1000      1000      5000                           0  \n",
       "4          1200      1100      1069      1000                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29996      5003      3047      5000      1000                           0  \n",
       "29997      8998       129         0         0                           0  \n",
       "29998     22000      4200      2000      3100                           1  \n",
       "29999      1178      1926     52964      1804                           1  \n",
       "30000      1430      1000      1000      1000                           1  \n",
       "\n",
       "[30001 rows x 25 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('./card_default.xls')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY_0',\n",
       "       'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'BILL_AMT2',\n",
       "       'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
       "       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',\n",
       "       'default payment next month'],\n",
       "      dtype='object', name=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.iloc[0]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ID                            object\n",
       "LIMIT_BAL                     object\n",
       "SEX                           object\n",
       "EDUCATION                     object\n",
       "MARRIAGE                      object\n",
       "AGE                           object\n",
       "PAY_0                         object\n",
       "PAY_2                         object\n",
       "PAY_3                         object\n",
       "PAY_4                         object\n",
       "PAY_5                         object\n",
       "PAY_6                         object\n",
       "BILL_AMT1                     object\n",
       "BILL_AMT2                     object\n",
       "BILL_AMT3                     object\n",
       "BILL_AMT4                     object\n",
       "BILL_AMT5                     object\n",
       "BILL_AMT6                     object\n",
       "PAY_AMT1                      object\n",
       "PAY_AMT2                      object\n",
       "PAY_AMT3                      object\n",
       "PAY_AMT4                      object\n",
       "PAY_AMT5                      object\n",
       "PAY_AMT6                      object\n",
       "default payment next month    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ID                            0\n",
       "LIMIT_BAL                     0\n",
       "SEX                           0\n",
       "EDUCATION                     0\n",
       "MARRIAGE                      0\n",
       "AGE                           0\n",
       "PAY_0                         0\n",
       "PAY_2                         0\n",
       "PAY_3                         0\n",
       "PAY_4                         0\n",
       "PAY_5                         0\n",
       "PAY_6                         0\n",
       "BILL_AMT1                     0\n",
       "BILL_AMT2                     0\n",
       "BILL_AMT3                     0\n",
       "BILL_AMT4                     0\n",
       "BILL_AMT5                     0\n",
       "BILL_AMT6                     0\n",
       "PAY_AMT1                      0\n",
       "PAY_AMT2                      0\n",
       "PAY_AMT3                      0\n",
       "PAY_AMT4                      0\n",
       "PAY_AMT5                      0\n",
       "PAY_AMT6                      0\n",
       "default payment next month    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('./card_payments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Data_prep\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---------+--------+---+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+\n",
      "| ID|LIMIT_BAL|SEX|EDUCATION|MARRIAGE|AGE|PAY_0|PAY_2|PAY_3|PAY_4|PAY_5|PAY_6|BILL_AMT1|BILL_AMT2|BILL_AMT3|BILL_AMT4|BILL_AMT5|BILL_AMT6|PAY_AMT1|PAY_AMT2|PAY_AMT3|PAY_AMT4|PAY_AMT5|PAY_AMT6|default payment next month|\n",
      "+---+---------+---+---------+--------+---+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+\n",
      "|  1|    20000|  2|        2|       1| 24|    2|    2|   -1|   -1|   -2|   -2|     3913|     3102|      689|        0|        0|        0|       0|     689|       0|       0|       0|       0|                         1|\n",
      "|  2|   120000|  2|        2|       2| 26|   -1|    2|    0|    0|    0|    2|     2682|     1725|     2682|     3272|     3455|     3261|       0|    1000|    1000|    1000|       0|    2000|                         1|\n",
      "|  3|    90000|  2|        2|       2| 34|    0|    0|    0|    0|    0|    0|    29239|    14027|    13559|    14331|    14948|    15549|    1518|    1500|    1000|    1000|    1000|    5000|                         0|\n",
      "|  4|    50000|  2|        2|       1| 37|    0|    0|    0|    0|    0|    0|    46990|    48233|    49291|    28314|    28959|    29547|    2000|    2019|    1200|    1100|    1069|    1000|                         0|\n",
      "|  5|    50000|  1|        2|       1| 57|   -1|    0|   -1|    0|    0|    0|     8617|     5670|    35835|    20940|    19146|    19131|    2000|   36681|   10000|    9000|     689|     679|                         0|\n",
      "+---+---------+---+---------+--------+---+-----+-----+-----+-----+-----+-----+---------+---------+---------+---------+---------+---------+--------+--------+--------+--------+--------+--------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('./card_payments.csv', header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'LIMIT_BAL',\n",
       " 'SEX',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_0',\n",
       " 'PAY_2',\n",
       " 'PAY_3',\n",
       " 'PAY_4',\n",
       " 'PAY_5',\n",
       " 'PAY_6',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'default payment next month']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'LIMIT_BAL',\n",
       " 'SEX',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_0',\n",
       " 'PAY_2',\n",
       " 'PAY_3',\n",
       " 'PAY_4',\n",
       " 'PAY_5',\n",
       " 'PAY_6',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'default payment next month'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert the categorical labels in the 'Species' column to numerical values\n",
    "label_indexer = StringIndexer(inputCol=target, outputCol=\"label\")\n",
    "data = label_indexer.fit(df).transform(df)\n",
    "\n",
    "# Assemble the feature columns into a single vector column\n",
    "assembler = VectorAssembler(inputCols=predictors, outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "model = dt_classifier.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8197\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.classification import LogisticRegression \n",
    "  \n",
    "log_reg = LogisticRegression(labelCol=\"label\", featuresCol=\"features\") \n",
    "  \n",
    "model = log_reg.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.transform(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8073\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(results)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "rfModel = rf.fit(train_data)\n",
    "predictions = rfModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy','weightedPrecision','weightedRecall','f1']\n",
    "m_df = pd.DataFrame(columns=metrics)\n",
    "m_ls = []\n",
    "for metric in metrics:\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=metric)\n",
    "    metric_ = evaluator.evaluate(predictions)\n",
    "    m_ls.append(metric_)\n",
    "m_df.loc[len(m_df)] = m_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_pd = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.810322</td>\n",
       "      <td>0.792482</td>\n",
       "      <td>0.810322</td>\n",
       "      <td>0.77974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  Accuracy  Precision    Recall       F1\n",
       "0    RF  0.810322   0.792482  0.810322  0.77974"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_pd = pd.concat([performance_pd, pd.DataFrame({'model':\"RF\", \n",
    "                                                    'Accuracy': m_df['accuracy'], \n",
    "                                                    'Precision': m_df['weightedPrecision'], \n",
    "                                                    'Recall': m_df['weightedRecall'],\n",
    "                                                    'F1': m_df['f1'],\n",
    "                                                     }, index=[0])])\n",
    "performance_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"model\", StringType(), True),\n",
    "    StructField(\"Accuracy\", DoubleType(), True),\n",
    "    StructField(\"Precision\", DoubleType(), True),\n",
    "    StructField(\"Recall\", DoubleType(), True),\n",
    "    StructField(\"F1\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_spark = spark.createDataFrame(performance_pd, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+------------------+------------------+\n",
      "|model|          Accuracy|         Precision|            Recall|                F1|\n",
      "+-----+------------------+------------------+------------------+------------------+\n",
      "|   RF|0.8103217158176944|0.7924823712226357|0.8103217158176944|0.7797398435038092|\n",
      "+-----+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(train_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Assuming 'label' is your label column\n",
    "train_data = train_data.withColumn(\"default payment next month\", when(df[\"default payment next month\"] == 1.0, 1.0).otherwise(0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "layers = [27, 15, 14, 1]\n",
    "mlf = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "mlfModel = mlf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlfModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'label', predictionCol = 'prediction', metricName = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEV01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
